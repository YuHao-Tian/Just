loading annotations into memory...
Done (t=6.54s)
creating index...
index created!
[info] subset = 10 images
==== RAW REPLY (image 1: 000000397133.jpg) ====
{"detections":[{"label":"person","box":[0.68,0.13,0.88,0.49],"confidence":0.99},{"label":"person","box":[0.68,0.13,0.88,0.49],"confidence":0.99}]}
[1/10] dt=2
==== RAW REPLY (image 2: 000000037777.jpg) ====
{"detections":[]}
[2/10] dt=2
==== RAW REPLY (image 3: 000000252219.jpg) ====
{"detections":[{"label":"person","box":[0.52, 0.3, 0.69, 0.82], "confidence":0.55}, {"label":"traffic light","box":[0.62, 0.0, 0.82, 0.22], "confidence":0.55}, {"label":"bicycle","box":[0.0, 0.49, 0.42, 0.89], "confidence":0.55}]}
[3/10] dt=5
==== RAW REPLY (image 4: 000000087038.jpg) ====
{"detections":[{"label":"person","box":[0.34,0.39,0.48,0.56],"confidence":0.85},{"label":"bicycle","box":[0.34,0.58,0.48,0.68],"confidence":0.85},{"label":"car","box":[0.0,0.58,0.1,0.68],"confidence":0.85},{"label":"motorcycle","box":[0.34,0.58,0.48,0.68],"confidence":0.85},{"label":"airplane","box":[0.0,0.58,0.1,0.68],"confidence":0.85},
[4/10] dt=5
==== RAW REPLY (image 5: 000000174482.jpg) ====
{"detections":[{"label":"bicycle","box":[0.22,0.13,0.79,0.99],"confidence":0.99},{"label":"car","box":[0.0,0.18,0.22,0.28],"confidence":0.99},{"label":"motorcycle","box":[0.54,0.19,0.75,0.34],"confidence":0.99},{"label":"truck","box":[0.79,0.18,0.92,0.28],"confidence":0.99}]}
[5/10] dt=9
[6/10] dt=9
[7/10] dt=10
[8/10] dt=11
[9/10] dt=11
[10/10] dt=11
[saved] detections -> /home/vipuser/coco/llava_dt_base.json
[info] JSON success rate: 10/10 = 100.00%
[time] processed 10 images in 22.6s
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=4.89s).
Accumulating evaluation results...
DONE (t=0.77s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
[metrics] mAP@[.50:.95]=0.0001 | AP50=0.0002 | AR@100=0.0000

------------------------------------------
Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003
[metrics] mAP@[.50:.95]=0.0010 | AP50=0.0036 | AR@100=0.0012

-------------------------------------------------------------------------
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.018
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.016
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.011
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.012
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.034
[metrics] mAP@[.50:.95]=0.0055 | AP50=0.0180 | AR@100=0.0122

------------------------------------------------------------

Got unknown args, potentially deprecated arguments: ['--image_folder', '/home/vipuser/coco/images']
Traceback (most recent call last):
  File "/home/vipuser/llavaenv/bin/llamafactory-cli", line 7, in <module>
    sys.exit(main())
  File "/home/vipuser/llavaenv/lib/python3.10/site-packages/llamafactory/cli.py", line 151, in main
    COMMAND_MAP[command]()
  File "/home/vipuser/llavaenv/lib/python3.10/site-packages/llamafactory/train/tuner.py", line 110, in run_exp
    _training_function(config={"args": args, "callbacks": callbacks})
  File "/home/vipuser/llavaenv/lib/python3.10/site-packages/llamafactory/train/tuner.py", line 55, in _training_function
    model_args, data_args, training_args, finetuning_args, generating_args = get_train_args(args)
  File "/home/vipuser/llavaenv/lib/python3.10/site-packages/llamafactory/hparams/parser.py", line 208, in get_train_args
    model_args, data_args, training_args, finetuning_args, generating_args = _parse_train_args(args)
  File "/home/vipuser/llavaenv/lib/python3.10/site-packages/llamafactory/hparams/parser.py", line 186, in _parse_train_args
    return _parse_args(parser, args, allow_extra_keys=allow_extra_keys)
  File "/home/vipuser/llavaenv/lib/python3.10/site-packages/llamafactory/hparams/parser.py", line 87, in _parse_args
    raise ValueError(f"Some specified arguments are not used by the HfArgumentParser: {unknown_args}")
ValueError: Some specified arguments are not used by the HfArgumentParser: ['--image_folder', '/home/vipuser/coco/images']
___________________
> import torch, sys
print("python:", sys.executable)
print("torch:", torch.__version__, "cuda_runtime_in_wheel:", torch.version.cuda) 
print("cuda_available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("device0:", torch.cuda.get_device_name(0))
    import torch.backends.cudnn as cudnn
    print("cudnn:", cudnn.version())
    # 做一次小算子，确保可用
    x = torch.randn(1024, 1024, device="cuda")
    y = x @ x.t()
    print("matmul_ok:", float(y[0,0]).__class__ is float or True)
> PY
python: /home/vipuser/miniforge3/envs/lf/bin/python
torch: 2.8.0+cu128 cuda_runtime_in_wheel: 12.8
cuda_available: True
device0: NVIDIA A100-SXM4-40GB
cudnn: 91002
matmul_ok: True
_________________________________________
[INFO|trainer.py:2433] 2025-08-19 10:04:29,322 >> ***** Running training *****
[INFO|trainer.py:2434] 2025-08-19 10:04:29,322 >>   Num examples = 10
[INFO|trainer.py:2435] 2025-08-19 10:04:29,323 >>   Num Epochs = 5
[INFO|trainer.py:2436] 2025-08-19 10:04:29,323 >>   Instantaneous batch size per device = 2
[INFO|trainer.py:2439] 2025-08-19 10:04:29,323 >>   Total train batch size (w. parallel, distributed & accumulation) = 16
[INFO|trainer.py:2440] 2025-08-19 10:04:29,323 >>   Gradient Accumulation steps = 8
[INFO|trainer.py:2441] 2025-08-19 10:04:29,323 >>   Total optimization steps = 5
[INFO|trainer.py:2442] 2025-08-19 10:04:29,332 >>   Number of trainable parameters = 19,988,480
  0%|          | 0/5 [00:00<?, ?it/s][WARNING|logging.py:328] 2025-08-19 10:04:31,804 >> `loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.
 40%|████      | 2/5 [00:21<00:31, 10.36s/it]

[INFO|tokenization_utils_base.py:2393] 2025-08-19 10:05:22,391 >> chat template saved in trainer_output/chat_template.jinja
[INFO|tokenization_utils_base.py:2562] 2025-08-19 10:05:22,392 >> tokenizer config file saved in trainer_output/tokenizer_config.json
[INFO|tokenization_utils_base.py:2571] 2025-08-19 10:05:22,392 >> Special tokens file saved in trainer_output/special_tokens_map.json
[INFO|modelcard.py:456] 2025-08-19 10:05:22,421 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
{'train_runtime': 52.5897, 'train_samples_per_second': 1.521, 'train_steps_per_second': 0.095, 'train_loss': 1.0642495155334473, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  total_flos               =  3643301GF
  train_loss               =     1.0642
  train_runtime            = 0:00:52.58
  train_samples_per_second =      1.521
  train_steps_per_second   =      0.095


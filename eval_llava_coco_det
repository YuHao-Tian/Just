#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Robust COCO eval for LLaVA-style VLMs (BASE vs LoRA)
- Strict-JSON prompting
- Resilient JSON parsing with light repairs + retries
- Per-class NMS + global NMS + confidence filter + max objects
- Deterministic decoding (do_sample=False)

Usage (examples):
  python -u eval_llava_coco_det.py \
    --model-dir /home/vipuser/llava-1.5-7b-hf \
    --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
    --val-img  /home/vipuser/coco/images/val2017 \
    --subset 500 \
    --tokens 1024 --min-conf 0.30 --nms-iou 0.60 --max-objects 12 \
    --out /home/vipuser/coco/llava_dt_BASE_500.json

  python -u eval_llava_coco_det.py \
    --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_merged \
    --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
    --val-img  /home/vipuser/coco/images/val2017 \
    --subset 500 \
    --tokens 1024 --min-conf 0.30 --nms-iou 0.60 --max-objects 12 \
    --out /home/vipuser/coco/llava_dt_LORA_500.json
"""

import os
import re
import json
import argparse
from typing import Any, Dict, List, Optional, Tuple

import torch
from PIL import Image
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval
from transformers import AutoProcessor, LlavaForConditionalGeneration

# ---------------------------
# Utility: IoU & NMS (xywh)
# ---------------------------

def iou_xywh(b1: List[float], b2: List[float]) -> float:
    x1, y1, w1, h1 = b1
    x2, y2, w2, h2 = b2
    xa1, ya1, xa2, ya2 = x1, y1, x1 + w1, y1 + h1
    xb1, yb1, xb2, yb2 = x2, y2, x2 + w2, y2 + h2
    inter_w = max(0.0, min(xa2, xb2) - max(xa1, xb1))
    inter_h = max(0.0, min(ya2, yb2) - max(ya1, yb1))
    inter = inter_w * inter_h
    union = w1 * h1 + w2 * h2 - inter + 1e-6
    return inter / union


def nms_xywh(dets: List[Dict[str, Any]], iou_thr: float) -> List[Dict[str, Any]]:
    # dets: dicts with keys: bbox(list[4]), score(float), category_id(int)
    dets_sorted = sorted(dets, key=lambda d: float(d.get("score", 0.0)), reverse=True)
    keep: List[Dict[str, Any]] = []
    for d in dets_sorted:
        ok = True
        for k in keep:
            if iou_xywh(d["bbox"], k["bbox"]) > iou_thr:
                ok = False
                break
        if ok:
            keep.append(d)
    return keep


# -----------------------------------
# JSON parsing (resilient, light repair)
# -----------------------------------

def strip_code_fences(text: str) -> str:
    t = text.strip()
    if t.startswith("```"):
        # remove leading fence
        t = re.sub(r"^```[a-zA-Z0-9]*\n?", "", t).strip()
        # remove trailing fence
        if t.endswith("```"):
            t = t[:-3].strip()
    return t


def try_loads(s: str) -> Optional[Any]:
    try:
        return json.loads(s)
    except Exception:
        return None


def recover_json_object(text: str) -> Dict[str, Any]:
    """
    Try to extract a single JSON object from raw text.
    Strategy:
      1) strip code fences
      2) take substring from first '{' to last '}' and json.loads
      3) attempt a few common suffix patches
      4) fallback to empty structure
    """
    t = strip_code_fences(text)
    s = t.find("{")
    e = t.rfind("}")
    if s != -1 and e != -1 and e > s:
        core = t[s : e + 1]
        obj = try_loads(core)
        if obj is not None:
            return obj
        # suffix patches
        for suff in ["}]}", "}}", "]}", "}"]:
            obj = try_loads(core + suff)
            if obj is not None:
                return obj
    # last-chance: find the first {...} block via regex (non-greedy)
    m = re.search(r"\{.*\}", t, flags=re.DOTALL)
    if m:
        obj = try_loads(m.group(0))
        if obj is not None:
            return obj
    return {"detections": []}


# ----------------------------------
# Label canonicalization & COCO maps
# ----------------------------------

COMMON_ALIASES = {
    "tv": "tv",
    "television": "tv",
    "tv monitor": "tv",
    "tvmonitor": "tv",
    "motorbike": "motorcycle",
    "aeroplane": "airplane",
    "trafficlight": "traffic light",
    "hydrant": "fire hydrant",
    "sofa": "couch",
    "bike": "bicycle",
    "sportsball": "sports ball",
}


def canon_label(name: str, valid: set) -> Optional[str]:
    n = (name or "").strip().lower()
    n = n.replace("_", " ")
    if n in COMMON_ALIASES:
        n = COMMON_ALIASES[n]
    # try singular heuristics for a few easy cases
    if n.endswith("s") and n[:-1] in valid:
        n = n[:-1]
    return n if n in valid else None


# -----------------------
# Build strict JSON prompt
# -----------------------

def build_prompt(class_names: List[str], max_objects: int) -> str:
    cls_str = ", ".join(class_names)
    instr = (
        "<image>\n"
        "Detect objects in the image and return ONLY ONE valid JSON object with key 'detections'.\n"
        "Each item: {\"label\":\"<one_of_COCO80>\", \"box\":[x1,y1,x2,y2], \"confidence\":0.xx}.\n"
        "Rules: coordinates are normalized floats in [0,1], top-left (x1,y1), bottom-right (x2,y2), x1<x2, y1<y2.\n"
        "Round numbers to 3 decimals. Use ONLY these labels (singular, English): "
        + cls_str + ".\n"
        f"At most {max_objects} objects. Omit low-confidence objects.\n"
        "No markdown, no code fences, no explanations. Output JSON only."
    )
    return instr


# ----------------------
# Generation & extraction
# ----------------------

def generate_for_image(
    model,
    processor,
    image: Image.Image,
    prompt: str,
    max_new_tokens: int,
) -> str:
    """Use LLaVA chat template so special tokens are correct."""
    messages = [
        {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": prompt}]}
    ]
    chat = processor.apply_chat_template(messages, add_generation_prompt=True)
    inputs = processor(images=image, text=chat, return_tensors="pt").to(model.device)
    with torch.inference_mode():
        output_ids = model.generate(
            **inputs,
            do_sample=False,
            max_new_tokens=max_new_tokens,
        )
    text = processor.batch_decode(output_ids, skip_special_tokens=True)[0]
    return text


# --------------
# Main procedure
# --------------

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model-dir", required=True, type=str)
    parser.add_argument("--val-ann", required=True, type=str)
    parser.add_argument("--val-img", required=True, type=str)
    parser.add_argument("--subset", type=int, default=500, help="Evaluate on first N images (by COCO order)")
    parser.add_argument("--tokens", type=int, default=1024)
    parser.add_argument("--min-conf", type=float, default=0.30)
    parser.add_argument("--nms-iou", type=float, default=0.60)
    parser.add_argument("--max-objects", type=int, default=12)
    parser.add_argument("--out", required=True, type=str)
    parser.add_argument("--save-raw", action="store_true", help="Also save raw generations next to --out")
    parser.add_argument("--quiet", action="store_true", help="Suppress Transformers generation warnings")
    args = parser.parse_args()

    # Optional: suppress noisy generation warnings from Transformers
    if args.quiet:
        try:
            from transformers.utils import logging as hf_logging
            hf_logging.set_verbosity_error()
            import os as _os
            _os.environ["TRANSFORMERS_VERBOSITY"] = "error"
        except Exception:
            pass

    device = "cuda" if torch.cuda.is_available() else "cpu"

    # Load model & processor
    print(f"[Load] Model from {args.model_dir}")
    model = LlavaForConditionalGeneration.from_pretrained(
        args.model_dir,
        torch_dtype=torch.float16 if device == "cuda" else torch.float32,
        device_map="auto" if device == "cuda" else None,
    )
    processor = AutoProcessor.from_pretrained(args.model_dir)

    # Load COCO
    print(f"[COCO] Anns: {args.val_ann}\n[COCO] Images dir: {args.val_img}")
    coco = COCO(args.val_ann)
    img_ids = coco.getImgIds()
    if args.subset and args.subset > 0:
        img_ids = img_ids[: args.subset]

    cats = coco.loadCats(coco.getCatIds())
    id2name = {c["id"]: c["name"].strip().lower() for c in cats}
    name2id = {v: k for k, v in id2name.items()}
    class_names = [id2name[i] for i in sorted(id2name.keys())]  # 80 names
    valid_names = set(class_names)

    # Prompt
    prompt = build_prompt(class_names, args.max_objects)
    retry_msg = "Only output a single valid JSON object with the key 'detections'. No extra words."

    # Prepare output containers
    dt: List[Dict[str, Any]] = []  # detections for COCOeval
    raw_texts: List[Tuple[int, str]] = []

    # Iterate images
    print(f"[Eval] Images: {len(img_ids)} | tokens={args.tokens} min_conf={args.min_conf} nms_iou={args.nms_iou} max_objects={args.max_objects}")

    for i, img_id in enumerate(img_ids, 1):
        info = coco.loadImgs([img_id])[0]
        file_name = info["file_name"]
        W, H = int(info["width"]), int(info["height"])
        img_path = os.path.join(args.val_img, file_name)
        try:
            image = Image.open(img_path).convert("RGB")
        except Exception as e:
            print(f"[Warn] Failed to open image {img_path}: {e}")
            continue

        # 1) first attempt
        text = generate_for_image(model, processor, image, prompt, max_new_tokens=args.tokens)
        obj = recover_json_object(text)

        # Validate basic structure; if bad, try a stricter retry prompt
        if not isinstance(obj, dict) or "detections" not in obj:
            # second attempt: prepend stricter instruction
            second_prompt = "<image>\n" + retry_msg
            text2 = generate_for_image(model, processor, image, second_prompt, max_new_tokens=args.tokens)
            obj = recover_json_object(text2)
            # keep the more promising raw
            text = text2 if len(json.dumps(obj)) > len(json.dumps(recover_json_object(text))) else text

        if args.save_raw:
            raw_texts.append((img_id, text))

        # Parse detections
        dets = obj.get("detections", [])
        if not isinstance(dets, list):
            dets = []

        raw: List[Dict[str, Any]] = []
        for d in dets[: (args.max_objects * 2)]:  # allow a bit more then prune via NMS
            if not isinstance(d, dict) or "box" not in d:
                continue
            lab_raw = str(d.get("label", ""))
            lab = canon_label(lab_raw, valid_names)
            if lab is None:
                continue
            try:
                x1, y1, x2, y2 = d["box"]
                x1 = float(x1); y1 = float(y1); x2 = float(x2); y2 = float(y2)
            except Exception:
                continue
            # clip & order
            x1 = max(0.0, min(1.0, x1))
            y1 = max(0.0, min(1.0, y1))
            x2 = max(0.0, min(1.0, x2))
            y2 = max(0.0, min(1.0, y2))
            if x2 <= x1 or y2 <= y1:
                continue
            # normalize->abs xywh
            x = x1 * W
            y = y1 * H
            w = (x2 - x1) * W
            h = (y2 - y1) * H
            if w <= 1 or h <= 1:
                continue
            # prefer explicit "confidence"; fall back to "score"; default 0.5
            score = d.get("confidence", d.get("score", 0.5))
            try:
                score = float(score)
            except Exception:
                score = 0.5
            # clamp to [0,1]
            if score < 0.0:
                score = 0.0
            if score > 1.0:
                score = 1.0
            raw.append({
                "image_id": int(img_id),
                "category_id": int(name2id[lab]),
                "bbox": [float(x), float(y), float(w), float(h)],
                "score": float(score),
            })

        # 1) confidence filter
        kept = [r for r in raw if r["score"] >= args.min_conf]

        # 2) per-class NMS
        by_cls: Dict[int, List[Dict[str, Any]]] = {}
        for r in kept:
            by_cls.setdefault(int(r["category_id"]), []).append(r)
        kept2: List[Dict[str, Any]] = []
        for cid, items in by_cls.items():
            kept2.extend(nms_xywh(items, args.nms_iou))

        # 3) global NMS (optional but helpful to reduce cross-class near-duplicates)
        kept3 = nms_xywh(kept2, args.nms_iou)

        # 4) cap number of objects
        kept3 = sorted(kept3, key=lambda d: d["score"], reverse=True)[: args.max_objects]

        dt.extend(kept3)

        if i % 50 == 0:
            print(f"  processed {i}/{len(img_ids)} images, current dt={len(dt)}")

    # Save detections
    out_path = args.out
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(dt, f)
    print(f"[Save] Detections -> {out_path} ({len(dt)} items)")

    if args.save_raw:
        raw_path = os.path.splitext(out_path)[0] + ".raw.txt"
        with open(raw_path, "w", encoding="utf-8") as f:
            for img_id, t in raw_texts:
                f.write(f"# image_id={img_id}\n{t}\n\n")
        print(f"[Save] Raw generations -> {raw_path}")

    # COCOeval
    print("[COCOeval] Running evaluation…")
    cocoDt = coco.loadRes(out_path) if len(dt) > 0 else None
    if cocoDt is None:
        print("[Warn] No detections, skipping COCOeval.")
        return

    coco_eval = COCOeval(coco, cocoDt, iouType="bbox")
    coco_eval.evaluate()
    coco_eval.accumulate()
    coco_eval.summarize()

    # Pretty print key metrics
    # coco_eval.stats: [AP, AP50, AP75, APs, APm, APl, AR1, AR10, AR100, ARs, ARm, ARl]
    AP = coco_eval.stats[0]
    AP50 = coco_eval.stats[1]
    AR100 = coco_eval.stats[8]
    print("==== SUMMARY ====")
    print(f"mAP@[.50:.95]: {AP:.4f}")
    print(f"AP50:          {AP50:.4f}")
    print(f"AR@100:        {AR100:.4f}")


if __name__ == "__main__":
    main()

{
  "coco_detjson_train": {
    "file_name": "train2017_detjson_abs.jsonl",
    "formatting": "sharegpt",
    "columns": { "messages": "conversations", "images": "images" },
    "tags": { "role_tag": "from", "content_tag": "value", "user_tag": "user", "assistant_tag": "assistant" },
    "multi_modal": true
  },
  "coco_detjson_val": {
    "file_name": "val2017_detjson_abs.jsonl",
    "formatting": "sharegpt",
    "columns": { "messages": "conversations", "images": "images" },
    "tags": { "role_tag": "from", "content_tag": "value", "user_tag": "user", "assistant_tag": "assistant" },
    "multi_modal": true
  }
}




——————————————————————————————————————————————————
# 随机抽两行确认 images 为“单元素列表 + 绝对路径”
python - <<'PY'
import json, os, random
for p in ["/home/vipuser/lf_data/train2017_detjson_abs.jsonl",
          "/home/vipuser/lf_data/val2017_detjson_abs.jsonl"]:
    with open(p) as f:
        lines = [next(f) for _ in range(2)]
    for line in lines:
        o = json.loads(line)
        imgs = o.get("images", [])
        assert isinstance(imgs, list) and len(imgs)==1, "images must be single-item list"
        assert imgs[0].startswith("/home/vipuser/coco/images/") and os.path.exists(imgs[0])
print("OK: images column looks good.")
PY


————————————————————————————————————————————————————————————
source ~/llavaenv/bin/activate

llamafactory-cli train \
  --stage sft \
  --finetuning_type lora \
  --model_name_or_path /home/vipuser/llava-1.5-7b-hf \
  --dataset_dir /home/vipuser/lf_data \
  --dataset coco_detjson_train \
  --eval_dataset coco_detjson_val \
  --template llava \
  --cutoff_len 1024 \
  --learning_rate 5e-05 \
  --num_train_epochs 3 \
  --per_device_train_batch_size 2 \
  --gradient_accumulation_steps 8 \
  --lora_rank 8 \
  --lora_alpha 16 \
  --lora_dropout 0.1 \
  --lora_target all \
  --output_dir /home/vipuser/saves/lf_llava15_7b_coco_loraB

___________________________________
ValueError: The number of images does not match the number of <image> tokens in [{'content': '<image>\nYou are an object detection assistant. Return ONLY a valid JSON object with key \'detections\'. Each item: {"label": <one of COCO-80>, "box": [x1,y1,x2,y2], "confidence": [0,1]}. Coordinates are normalized to [0,1] with (x1,y1)=top-left and (x2,y2)=bottom-right. If nothing is found, return {"detections":[]}. Output JSON only.', 'role': 'user'}, {'content': '{"detections": [{"label": "motorcycle", "box": [0.561203125, 0.40602777777777777, 0.73690625, 0.9992777777777778], "confidence": 1.0}, {"label": "person", "box": [0.5310625, 0.06155555555555556, 0.7715, 0.8969166666666668], "confidence": 1.0}, {"label": "person", "box": [0.7369375, 0.4800555555555555, 0.7930625, 0.6136666666666666], "confidence": 1.0}, {"label": "bicycle", "box": [0.759390625, 0.5091944444444445, 0.80725, 0.6063611111111111], "confidence": 1.0}]}', 'role': 'assistant'}].

________________________
   {"id": "coco_train2017_391895", "images": ["/home/vipuser/coco/images/train2017/000000391895.jpg"], "conversations": [{"from": "user", "value": "<image>\nYou are an object detection assistant. Return ONLY a valid JSON object with key 'detections'. Each item: {\"label\": <one of COCO-80>, \"box\": [x1,y1,x2,y2], \"confidence\": [0,1]}. Coordinates are normalized to [0,1] with (x1,y1)=top-left and (x2,y2)=bottom-right. If nothing is found, return {\"detections\":[]}. Output JSON only."}, {"from": "assistant", "value": "{\"detections\": [{\"label\": \"motorcycle\", \"box\": [0.561203125, 0.40602777777777777, 0.73690625, 0.9992777777777778], \"confidence\": 1.0}, {\"label\": \"person\", \"box\": [0.5310625, 0.06155555555555556, 0.7715, 0.8969166666666668], \"confidence\": 1.0}, {\"label\": \"person\", \"box\": [0.7369375, 0.4800555555555555, 0.7930625, 0.6136666666666666], \"confidence\": 1.0}, {\"label\": \"bicycle\", \"box\": [0.759390625, 0.5091944444444445, 0.80725, 0.6063611111111111], \"confidence\": 1.0}]}"}]}

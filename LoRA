{
  "coco_detjson_train": {
    "file_name": "train2017_detjson_abs.jsonl",
    "formatting": "sharegpt",
    "columns": { "messages": "conversations" },
    "tags": { "role_tag": "from", "content_tag": "value", "user_tag": "user", "assistant_tag": "assistant" },
    "multi_modal": true,
    "image_field": "images",
    "image_column": "images"
  },
  "coco_detjson_val": {
    "file_name": "val2017_detjson_abs.jsonl",
    "formatting": "sharegpt",
    "columns": { "messages": "conversations" },
    "tags": { "role_tag": "from", "content_tag": "value", "user_tag": "user", "assistant_tag": "assistant" },
    "multi_modal": true,
    "image_field": "images",
    "image_column": "images"
  }
}

——————————————————————————————————————————————————
python - <<'PY'
import json, os, re
p="/home/vipuser/lf_data/train2017_detjson_abs.jsonl"
with open(p) as f:
    obj=json.loads(next(f))
msgs=[c["value"] for c in obj["conversations"]]
tokens=sum(len(re.findall(r"<image>", m)) for m in msgs)
imgs=obj.get("images", [])
print("tokens=", tokens, "imgs=", len(imgs), "ok=", tokens==len(imgs))
print("exists=", all(os.path.exists(x) for x in imgs), "example_img=", imgs[0] if imgs else None)
PY
————————————————————————————————————————————————————————————
source ~/llavaenv/bin/activate

llamafactory-cli train \
  --stage sft \
  --finetuning_type lora \
  --model_name_or_path /home/vipuser/llava-1.5-7b-hf \
  --dataset_dir /home/vipuser/lf_data \
  --dataset coco_detjson_train \
  --eval_dataset coco_detjson_val \
  --template llava \
  --cutoff_len 1024 \
  --learning_rate 5e-05 \
  --num_train_epochs 3 \
  --per_device_train_batch_size 2 \
  --gradient_accumulation_steps 8 \
  --lora_rank 8 \
  --lora_alpha 16 \
  --lora_dropout 0.1 \
  --lora_target all \
  --output_dir /home/vipuser/saves/lf_llava15_7b_coco_loraB

——————

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, json, argparse, time, re, math, collections
from typing import List, Dict, Any, Optional
import torch
from PIL import Image
from transformers import AutoProcessor, LlavaForConditionalGeneration
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval


# -------------------- utils --------------------

def clamp01(x: float) -> float:
    try:
        return max(0.0, min(1.0, float(x)))
    except Exception:
        return 0.0

def iou_xyxy(a: List[float], b: List[float]) -> float:
    ax1, ay1, ax2, ay2 = a
    bx1, by1, bx2, by2 = b
    ix1, iy1 = max(ax1, bx1), max(ay1, by1)
    ix2, iy2 = min(ax2, bx2), min(ay2, by2)
    iw, ih = max(0.0, ix2 - ix1), max(0.0, iy2 - iy1)
    inter = iw * ih
    if inter <= 0:
        return 0.0
    area_a = max(0.0, ax2 - ax1) * max(0.0, ay2 - ay1)
    area_b = max(0.0, bx2 - bx1) * max(0.0, by2 - by1)
    union = area_a + area_b - inter + 1e-12
    return inter / union

def nms_greedy(dets: List[Dict[str, Any]], iou_thr: float) -> List[Dict[str, Any]]:
    if not dets:
        return dets
    dets = sorted(dets, key=lambda d: float(d.get("confidence", 0.0)), reverse=True)
    keep, used = [], [False] * len(dets)
    for i, di in enumerate(dets):
        if used[i]:
            continue
        keep.append(di)
        bi = di["box"]
        for j in range(i + 1, len(dets)):
            if used[j]:
                continue
            bj = dets[j]["box"]
            if iou_xyxy(bi, bj) >= iou_thr:
                used[j] = True
    return keep

def _strip_code_fences(s: str) -> str:
    s = s.strip()
    if s.startswith("```"):
        s = re.sub(r"^```[a-zA-Z0-9]*\n?", "", s).strip()
        if s.endswith("```"):
            s = s[:-3].strip()
    return s

def extract_first_json(text: str) -> Optional[str]:
    """å°½é‡ä»è‡ªç”±æ–‡æœ¬æŠ“å‡ºä¸€ä¸ªåˆæ³• JSONï¼ˆå¯¹è±¡æˆ–æ•°ç»„ï¼‰"""
    text = _strip_code_fences(text)
    # å…ˆè¯•æ•´ä½“
    try:
        json.loads(text)
        return text
    except Exception:
        pass
    # å°è¯•å¯¹è±¡ {...}
    try:
        s = text.index("{")
        stack = 0
        for i in range(s, len(text)):
            if text[i] == "{": stack += 1
            elif text[i] == "}":
                stack -= 1
                if stack == 0:
                    cand = text[s:i+1]
                    json.loads(cand)
                    return cand
    except Exception:
        pass
    # å°è¯•æ•°ç»„ [...]
    try:
        s = text.index("[")
        stack = 0
        for i in range(s, len(text)):
            if text[i] == "[": stack += 1
            elif text[i] == "]":
                stack -= 1
                if stack == 0:
                    cand = text[s:i+1]
                    json.loads(cand)
                    return cand
    except Exception:
        pass
    return None

def coerce_conf(v) -> float:
    """æŠŠ confidence å˜æˆ 0..1 çš„ floatï¼›åˆ—è¡¨å– [0,1] èŒƒå›´å†…æœ€å¤§å€¼ï¼›å¥‡æ€ªæ ¼å¼é™ä¸º 0.0"""
    try:
        if isinstance(v, (list, tuple)):
            vals = [float(x) for x in v if isinstance(x, (int, float)) and 0.0 <= float(x) <= 1.0]
            if len(vals) == 0:
                return 0.0
            return float(max(vals))
        return clamp01(float(v))
    except Exception:
        return 0.0

def valid_box_norm(box) -> bool:
    if not isinstance(box, (list, tuple)) or len(box) != 4:
        return False
    try:
        x1, y1, x2, y2 = [clamp01(b) for b in box]
        return (x1 < x2) and (y1 < y2)
    except Exception:
        return False

# -------- label normalization (robust) --------

def build_canon_label(name2id: Dict[str, int]):
    """å°†æ¨¡å‹è¾“å‡ºçš„å„ç§å†™æ³•å½’ä¸€åˆ° COCO å®˜æ–¹å°å†™ç±»åï¼›ä¸è®¤è¯†çš„è¿”å› Noneï¼ˆåç»­ä¼šè·³è¿‡ï¼Œä¸æŠ¥é”™ï¼‰"""
    name_set = set(name2id.keys())
    no_space = {n.replace(" ", ""): n for n in name_set}

    synonyms = {
        "people":"person","man":"person","men":"person","woman":"person","women":"person",
        "boy":"person","girl":"person","kid":"person","child":"person","baby":"person",
        "motorbike":"motorcycle","bike":"bicycle","aeroplane":"airplane","aircraft":"airplane",
        "trafficlight":"traffic light","traffic-light":"traffic light",
        "tvmonitor":"tv","tv monitor":"tv","television":"tv",
        "cellphone":"cell phone","mobile phone":"cell phone","smartphone":"cell phone","iphone":"cell phone",
        "sofa":"couch","pottedplant":"potted plant","potted  plant":"potted plant",
        "diningtable":"dining table","hand bag":"handbag","hand-bag":"handbag",
        "wineglass":"wine glass","wine-glass":"wine glass",
        "tennis-racket":"tennis racket","baseball-bat":"baseball bat","baseball-glove":"baseball glove",
        # å¸¸è§å¸¦ä¿®é¥°è¯
        "baby giraffe":"giraffe","young giraffe":"giraffe","baby zebra":"zebra","baby elephant":"elephant",
        "baby cow":"cow","baby bear":"bear","baby person":"person"
    }
    # å»æ‰è¿™äº›ä¿®é¥°è¯åå†è¯•
    drop_words = {"baby","young","small","little","tiny","big","large","adult","male","female","brown","white","black","red","green","blue","yellow"}

    def canon(raw: str | None) -> Optional[str]:
        s = (raw or "").lower().strip().replace("_", " ").replace("-", " ")
        s = re.sub(r"\s+", " ", s)

        if s in name_set: return s
        if s in synonyms: return synonyms[s]
        key = s.replace(" ", "")
        if key in no_space: return no_space[key]

        # å»ä¿®é¥°è¯
        toks = [w for w in s.split() if w not in drop_words]
        s2 = " ".join(toks)
        if s2 in name_set: return s2
        if s2 in synonyms: return synonyms[s2]
        key2 = s2.replace(" ", "")
        if key2 in no_space: return no_space[key2]

        # åŒ…å«åŒ¹é…ï¼ˆä¼˜å…ˆé•¿è¯ï¼‰
        for cname in sorted(name_set, key=len, reverse=True):
            if cname in s2:
                return cname
        return None

    return canon


# -------------------- main --------------------

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--model-dir", required=True, help="LLaVA æ¨¡å‹ç›®å½•ï¼ˆåŸºåº§æˆ–åˆå¹¶åçš„ LoRAï¼‰")
    ap.add_argument("--val-ann", required=True, help="COCO instances_val2017.json")
    ap.add_argument("--val-img", required=True, help="COCO val2017 å›¾åƒç›®å½•")
    ap.add_argument("--subset", type=int, default=50, help="è¯„ä¼°å‰ N å¼ ï¼ˆ0=å…¨éƒ¨ï¼‰")
    ap.add_argument("--tokens", type=int, default=768, help="ç”Ÿæˆçš„æœ€å¤§æ–° token æ•°")
    ap.add_argument("--out", required=True, help="COCO æäº¤æ ¼å¼æ£€æµ‹ç»“æœ json è·¯å¾„")
    ap.add_argument("--max-objects", type=int, default=8, help="æ¯å›¾æœ€å¤šç›®æ ‡æ•°")
    ap.add_argument("--nms-iou", type=float, default=0.6, help="NMS IoU é˜ˆå€¼")
    ap.add_argument("--min-conf", type=float, default=0.30, help="æœ€å°ç½®ä¿¡åº¦")
    ap.add_argument("--show-raw", action="store_true", help="æ‰“å°å‰å‡ å¼ çš„åŸå§‹å›å¤")
    args = ap.parse_args()

    device = "cuda" if torch.cuda.is_available() else "cpu"
    prefer_bf16 = torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8
    dtype = torch.bfloat16 if prefer_bf16 else torch.float16 if device == "cuda" else torch.float32

    print(f"[info] loading model from: {args.model_dir}")
    try:
        model = LlavaForConditionalGeneration.from_pretrained(args.model_dir, torch_dtype=dtype)
    except Exception:
        # æŸäº›ç¯å¢ƒä¸æ”¯æŒ bf16ï¼Œå°±å›é€€ fp16
        model = LlavaForConditionalGeneration.from_pretrained(args.model_dir, torch_dtype=torch.float16)
    model.to(device).eval()
    proc = AutoProcessor.from_pretrained(args.model_dir)

    coco = COCO(args.val_ann)
    cats = coco.loadCats(coco.getCatIds())
    class_names = [c["name"] for c in cats]
    name2id = {c["name"].lower(): c["id"] for c in cats}
    canon_label = build_canon_label(name2id)
    allowed = set(name2id.keys())

    imgs = coco.dataset["images"]
    ids = [im["id"] for im in imgs]
    info = {im["id"]: (im["file_name"], im.get("width", 0), im.get("height", 0)) for im in imgs}
    if args.subset and args.subset > 0:
        ids = ids[:args.subset]
    print(f"[info] subset = {len(ids)} images")

    # æŒ‡ä»¤ï¼ˆä¸æ”¾ JSON æ ·ä¾‹ï¼Œå‡å°‘â€œç…§æŠ„æ¨¡æ¿â€ï¼‰
    instr = (
        "You are an object detection assistant. "
        "Return ONLY a valid JSON with key 'detections'. "
        'Each item: {"label": <one COCO class>, "box": [x1,y1,x2,y2], "confidence": [0,1]}. '
        "Coordinates are normalized to [0,1] with (x1,y1)=top-left and (x2,y2)=bottom-right. "
        f"At most {args.max_objects} objects. Do NOT repeat the same class or the same box. "
        "If two boxes IoU>0.6, keep the one with higher confidence. "
        "Use ONLY these labels (singular, English): " + ", ".join(class_names) + ". "
        'If nothing is found, return {"detections":[]}. '
        "Output JSON only."
    )

    def gen_and_decode(img, prompt, max_new_tokens):
        inputs = proc(images=img, text=prompt, return_tensors="pt")
        inputs = {k: (v.to(device) if hasattr(v, "to") else v) for k, v in inputs.items()}
        with torch.inference_mode():
            out = model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                do_sample=False,                # å…³é—­é‡‡æ ·ï¼Œç¨³å®šè¾“å‡º
                return_dict_in_generate=True
            )
        seq = out.sequences[0]
        gen_ids = seq[inputs["input_ids"].shape[-1]:]
        return proc.decode(gen_ids, skip_special_tokens=True).strip()

    all_dt = []
    ok_json = 0
    unk_counter = collections.Counter()
    t0 = time.time()

    for k, img_id in enumerate(ids, 1):
        fn, W, H = info[img_id]
        path = os.path.join(args.val_img, fn)
        img = Image.open(path).convert("RGB")

        messages = [{"role": "user", "content": [{"type": "image"}, {"type": "text", "text": instr}]}]
        prompt = proc.apply_chat_template(messages, add_generation_prompt=True)

        txt = gen_and_decode(img, prompt, args.tokens)

        # å¯é€‰ï¼šæ‰“å°å‰ 3 å¼ å›¾çš„åŸå§‹å›å¤
        if args.show_raw and k <= 3:
            print(f"==== RAW REPLY (image {k}: {fn}) ====")
            print(txt)

        js = extract_first_json(txt)
        dets_in = []
        if js is not None:
            try:
                obj = json.loads(js)
                if isinstance(obj, list):
                    obj = {"detections": obj}
                dets_in = obj.get("detections", []) if isinstance(obj, dict) else []
            except Exception:
                dets_in = []
        # æ— è®ºæ˜¯å¦ä¸ºç©ºï¼Œéƒ½å½“ä½œâ€œå¯è§£æä¸€æ¬¡â€
        ok_json += 1

        # å½’ä¸€ + è¿‡æ»¤ + ç½®ä¿¡åº¦å¤„ç†
        cleaned = []
        for d in dets_in if isinstance(dets_in, list) else []:
            raw_label = d.get("label", "")
            lab = canon_label(raw_label)
            if lab is None or lab not in allowed:
                # ç»Ÿè®¡æœªçŸ¥æ ‡ç­¾ä½†ä¸æŠ¥é”™
                if isinstance(raw_label, str) and raw_label:
                    unk_counter[raw_label.lower().strip()] += 1
                continue

            box = d.get("box", None)
            if not isinstance(box, (list, tuple)) or len(box) != 4:
                continue
            x1, y1, x2, y2 = [clamp01(b) for b in box]
            x1, x2 = min(x1, x2), max(x1, x2)
            y1, y2 = min(y1, y2), max(y1, y2)
            if not (x1 < x2 and y1 < y2):
                continue

            conf = coerce_conf(d.get("confidence", 0.0))
            if conf < args.min_conf:
                continue

            cleaned.append({"label": lab, "box": [x1, y1, x2, y2], "confidence": conf})

        # ç±»å†… & å…¨å±€ NMS
        by_cls = {}
        for d in cleaned:
            by_cls.setdefault(d["label"], []).append(d)
        merged = []
        for lab, group in by_cls.items():
            merged.extend(nms_greedy(group, iou_thr=args.nms_iou))
        merged = nms_greedy(merged, iou_thr=args.nms_iou)

        # åŒç±»ä»…ä¿ç•™æœ€é«˜åˆ†ï¼›é™åˆ¶æœ€å¤šæ•°é‡
        best_by_cls = {}
        for d in merged:
            lab = d["label"]
            if (lab not in best_by_cls) or (d["confidence"] > best_by_cls[lab]["confidence"]):
                best_by_cls[lab] = d
        final_dets = sorted(best_by_cls.values(), key=lambda x: x["confidence"], reverse=True)[:args.max_objects]

        # å†™ COCO æ ¼å¼
        for d in final_dets:
            lab = d["label"]  # å·²ç»æ˜¯æ ‡å‡†åŒ–çš„
            x1, y1, x2, y2 = d["box"]
            x, y, w, h = x1 * W, y1 * H, (x2 - x1) * W, (y2 - y1) * H
            all_dt.append({
                "image_id": int(img_id),
                "category_id": name2id[lab],
                "bbox": [float(x), float(y), float(w), float(h)],
                "score": float(clamp01(d["confidence"]))
            })

        print(f"[{k}/{len(ids)}] dt={len(final_dets)}")

    # ä¿å­˜ç»“æœ
    with open(args.out, "w") as f:
        json.dump(all_dt, f)
    print(f"[saved] detections -> {args.out}")
    jsucc = ok_json / max(1, len(ids))
    print(f"[info] JSON success rate: {ok_json}/{len(ids)} = {jsucc:.2%}")
    if unk_counter:
        topk = ", ".join([f"{k}:{v}" for k, v in unk_counter.most_common(5)])
        print(f"[info] skipped unknown labels (top): {topk}")
    print(f"[time] processed {len(ids)} images in {time.time() - t0:.1f}s")

    if len(all_dt) == 0:
        print("[warn] No detections recorded. mAP will be 0.0.")
        return

    # è¯„æµ‹
    res = coco.loadRes(args.out)
    e = COCOeval(coco, res, "bbox")
    e.evaluate(); e.accumulate(); e.summarize()
    mAP, AP50, AR100 = float(e.stats[0]), float(e.stats[1]), float(e.stats[8])
    print(f"[metrics] mAP@[.50:.95]={mAP:.4f} | AP50={AP50:.4f} | AR@100={AR100:.4f}")


if __name__ == "__main__":
    main()
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
python -u /home/vipuser/eval_llava_coco_det.py \
  --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_500imgs_merged \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 50 \
  --tokens 512 \
  --out /home/vipuser/coco/llava_dt_LORA_50.json \
  --show-raw
_________
# æ–¹æ¡ˆAï¼šç”¨ sed ä¸€æŠŠæ›¿æ¢ä¸¤ç§å†™æ³•
sed -i 's/args\.show-raw/args.show_raw/g; s/args\.show\b/args.show_raw/g' /home/vipuser/eval_llava_coco_det.py
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
python -u /home/vipuser/eval_llava_coco_det.py \
  --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_500imgs_merged \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 50 \
  --tokens 768 \
  --min-conf 0.30 \
  --nms-iou 0.60 \
  --max-objects 8 \
  --out /home/vipuser/coco/llava_dt_LORA_50.json \
  --show-raw

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
python -u /home/vipuser/eval_llava_coco_det.py \
  --model-dir /home/vipuser/llava-1.5-7b-hf \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 50 \
  --tokens 1024 \
  --max-objects 20 --min-conf 0.10 --nms-iou 0.5 \
  --out /home/vipuser/coco/llava_dt_BASE_50.json \
  --show-raw
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# åŸå§‹æ¨¡å‹ï¼ˆåŸºçº¿ï¼‰
python -u /home/vipuser/eval_llava_coco_det.py \
  --model-dir /home/vipuser/llava-1.5-7b-hf \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 500 \
  --tokens 1024 --min-conf 0.30 --nms-iou 0.60 --max-objects 12 \
  --out /home/vipuser/coco/llava_dt_BASE_500.json --save-raw

# LoRA åˆå¹¶åæ¨¡å‹
python -u /home/vipuser/eval_llava_coco_det.py \
  --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_merged \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 500 \
  --tokens 1024 --min-conf 0.30 --nms-iou 0.60 --max-objects 12 \
  --out /home/vipuser/coco/llava_dt_LORA_500.json --save-raw
_______________
# åŸºçº¿
~/miniforge3/envs/lf/bin/python -u /home/vipuser/eval_llava_coco_chat_SOLID.py \
  --model-dir /home/vipuser/llava-1.5-7b-hf \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 10 \
  --tokens 256 --min-conf 0.05 --nms-iou 0.60 --max-objects 12 \
  --out /home/vipuser/coco/smoke_BASE.json --save-raw
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# LoRAï¼ˆåˆå¹¶åï¼šç”¨ *_merged è¿™ä¸ªç›®å½•ï¼‰
python -u /home/vipuser/eval_llava_coco_chat_SOLID.py \
  --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_500imgs_merged \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 500 \
  --tokens 512 --min-conf 0.00 --nms-iou 0.60 --max-objects 50 \
  --out /home/vipuser/coco/LORA_500.json --save-raw
  â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# BASE
python -u /home/vipuser/eval_llava_coco_chat_SOLID.py \
  --model-dir /home/vipuser/llava-1.5-7b-hf \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 500 \
  --tokens 512 --min-conf 0.00 --nms-iou 0.60 --max-objects 50 \
  --out /home/vipuser/coco/BASE_500.json --save-raw

# LoRAï¼ˆç”¨ *_mergedï¼‰
python -u /home/vipuser/eval_llava_coco_chat_SOLID.py \
  --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_500imgs_merged \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 500 \
  --tokens 512 --min-conf 0.00 --nms-iou 0.60 --max-objects 50 \
  --out /home/vipuser/coco/LORA_500.json --save-raw
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# ä¾‹ï¼šç”¨åŸºåº§æ¨¡å‹ï¼Œå¯¹ COCO val2017 å‰ 50 å¼ åšâ€œè‡ªæŠ¥å‡†ç¡®ç‡â€
python -u /home/vipuser/selfreport_acc_llava.py \
  --model-dir /home/vipuser/llava-1.5-7b-hf \
  --val-img   /home/vipuser/coco/images/val2017 \
  --subset 50 \
  --tokens 256 \
  --out /home/vipuser/coco/self_acc_BASE_50.json \
  --save-raw
python -u /home/vipuser/selfreport_acc_llava.py \
  --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_500imgs_merged \
  --proc-dir  /home/vipuser/llava-1.5-7b-hf \
  --val-img   /home/vipuser/coco/images/val2017 \
  --subset 50 --tokens 256 \
  --out /home/vipuser/coco/self_acc_LORA_50.json --save-raw

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
source ~/miniforge3/envs/lf/bin/activate
python -u /home/vipuser/unified_llava_det.py \
  --model-dir /home/vipuser/llava-1.5-7b-hf \
  --image /home/vipuser/coco/images/val2017/000000397133.jpg \
  --tokens 256 --max-objects 20 --device-map cuda \
  --out-img  /home/vipuser/coco/vis_BASE_397133.jpg \
  --out-json /home/vipuser/coco/vis_BASE_397133.json \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --save-raw

python -u /home/vipuser/unified_llava_det.py \
  --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_500imgs_merged \
  --proc-dir  /home/vipuser/llava-1.5-7b-hf \
  --image /home/vipuser/coco/images/val2017/000000397133.jpg \
  --tokens 256 --max-objects 20 --device-map cuda \
  --out-img  /home/vipuser/coco/vis_LORA_397133.jpg \
  --out-json /home/vipuser/coco/vis_LORA_397133.json \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --save-raw
source ~/miniforge3/envs/lf/bin/activate

python -u /home/vipuser/unified_llava_det.py \
  --model-dir /home/vipuser/llava-1.5-7b-hf \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 500 \
  --tokens 768 --min-conf 0.30 --nms-iou 0.60 --max-objects 12 \
  --out /home/vipuser/coco/llava_dt_BASE_500.json \
  --save-raw --device-map cuda

python -u /home/vipuser/unified_llava_det.py \
  --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_500imgs_merged \
  --proc-dir  /home/vipuser/llava-1.5-7b-hf \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 500 \
  --tokens 768 --min-conf 0.30 --nms-iou 0.60 --max-objects 12 \
  --out /home/vipuser/coco/llava_dt_LORA_500.json \
  --save-raw --device-map cuda

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# åŸºåº§
python -u /home/vipuser/unified_llava_det.py \
  --model-dir /home/vipuser/llava-1.5-7b-hf \
  --image /home/vipuser/coco/images/val2017/000000397133.jpg \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \  # ğŸ‘ˆ å…³é”®ï¼šå¯ç”¨ COCO80 ç±»è¡¨
  --tokens 512 --max-objects 20 --min-conf 0.05 --device-map cuda \
  --out-img  /home/vipuser/coco/vis_BASE_397133.jpg \
  --out-json /home/vipuser/coco/vis_BASE_397133.json \
  --save-raw

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, json, argparse, time, re, math, collections
from typing import List, Dict, Any, Optional
import torch
from PIL import Image
from transformers import AutoProcessor, LlavaForConditionalGeneration
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval


# -------------------- utils --------------------

def clamp01(x: float) -> float:
    try:
        return max(0.0, min(1.0, float(x)))
    except Exception:
        return 0.0

def iou_xyxy(a: List[float], b: List[float]) -> float:
    ax1, ay1, ax2, ay2 = a
    bx1, by1, bx2, by2 = b
    ix1, iy1 = max(ax1, bx1), max(ay1, by1)
    ix2, iy2 = min(ax2, bx2), min(ay2, by2)
    iw, ih = max(0.0, ix2 - ix1), max(0.0, iy2 - iy1)
    inter = iw * ih
    if inter <= 0:
        return 0.0
    area_a = max(0.0, ax2 - ax1) * max(0.0, ay2 - ay1)
    area_b = max(0.0, bx2 - bx1) * max(0.0, by2 - by1)
    union = area_a + area_b - inter + 1e-12
    return inter / union

def nms_greedy(dets: List[Dict[str, Any]], iou_thr: float) -> List[Dict[str, Any]]:
    if not dets:
        return dets
    dets = sorted(dets, key=lambda d: float(d.get("confidence", 0.0)), reverse=True)
    keep, used = [], [False] * len(dets)
    for i, di in enumerate(dets):
        if used[i]:
            continue
        keep.append(di)
        bi = di["box"]
        for j in range(i + 1, len(dets)):
            if used[j]:
                continue
            bj = dets[j]["box"]
            if iou_xyxy(bi, bj) >= iou_thr:
                used[j] = True
    return keep

def _strip_code_fences(s: str) -> str:
    s = s.strip()
    if s.startswith("```"):
        s = re.sub(r"^```[a-zA-Z0-9]*\n?", "", s).strip()
        if s.endswith("```"):
            s = s[:-3].strip()
    return s

def extract_first_json(text: str) -> Optional[str]:
    """尽量从自由文本抓出一个合法 JSON（对象或数组）"""
    text = _strip_code_fences(text)
    # 先试整体
    try:
        json.loads(text)
        return text
    except Exception:
        pass
    # 尝试对象 {...}
    try:
        s = text.index("{")
        stack = 0
        for i in range(s, len(text)):
            if text[i] == "{": stack += 1
            elif text[i] == "}":
                stack -= 1
                if stack == 0:
                    cand = text[s:i+1]
                    json.loads(cand)
                    return cand
    except Exception:
        pass
    # 尝试数组 [...]
    try:
        s = text.index("[")
        stack = 0
        for i in range(s, len(text)):
            if text[i] == "[": stack += 1
            elif text[i] == "]":
                stack -= 1
                if stack == 0:
                    cand = text[s:i+1]
                    json.loads(cand)
                    return cand
    except Exception:
        pass
    return None

def coerce_conf(v) -> float:
    """把 confidence 变成 0..1 的 float；列表取 [0,1] 范围内最大值；奇怪格式降为 0.0"""
    try:
        if isinstance(v, (list, tuple)):
            vals = [float(x) for x in v if isinstance(x, (int, float)) and 0.0 <= float(x) <= 1.0]
            if len(vals) == 0:
                return 0.0
            return float(max(vals))
        return clamp01(float(v))
    except Exception:
        return 0.0

def valid_box_norm(box) -> bool:
    if not isinstance(box, (list, tuple)) or len(box) != 4:
        return False
    try:
        x1, y1, x2, y2 = [clamp01(b) for b in box]
        return (x1 < x2) and (y1 < y2)
    except Exception:
        return False

# -------- label normalization (robust) --------

def build_canon_label(name2id: Dict[str, int]):
    """将模型输出的各种写法归一到 COCO 官方小写类名；不认识的返回 None（后续会跳过，不报错）"""
    name_set = set(name2id.keys())
    no_space = {n.replace(" ", ""): n for n in name_set}

    synonyms = {
        "people":"person","man":"person","men":"person","woman":"person","women":"person",
        "boy":"person","girl":"person","kid":"person","child":"person","baby":"person",
        "motorbike":"motorcycle","bike":"bicycle","aeroplane":"airplane","aircraft":"airplane",
        "trafficlight":"traffic light","traffic-light":"traffic light",
        "tvmonitor":"tv","tv monitor":"tv","television":"tv",
        "cellphone":"cell phone","mobile phone":"cell phone","smartphone":"cell phone","iphone":"cell phone",
        "sofa":"couch","pottedplant":"potted plant","potted  plant":"potted plant",
        "diningtable":"dining table","hand bag":"handbag","hand-bag":"handbag",
        "wineglass":"wine glass","wine-glass":"wine glass",
        "tennis-racket":"tennis racket","baseball-bat":"baseball bat","baseball-glove":"baseball glove",
        # 常见带修饰词
        "baby giraffe":"giraffe","young giraffe":"giraffe","baby zebra":"zebra","baby elephant":"elephant",
        "baby cow":"cow","baby bear":"bear","baby person":"person"
    }
    # 去掉这些修饰词后再试
    drop_words = {"baby","young","small","little","tiny","big","large","adult","male","female","brown","white","black","red","green","blue","yellow"}

    def canon(raw: str | None) -> Optional[str]:
        s = (raw or "").lower().strip().replace("_", " ").replace("-", " ")
        s = re.sub(r"\s+", " ", s)

        if s in name_set: return s
        if s in synonyms: return synonyms[s]
        key = s.replace(" ", "")
        if key in no_space: return no_space[key]

        # 去修饰词
        toks = [w for w in s.split() if w not in drop_words]
        s2 = " ".join(toks)
        if s2 in name_set: return s2
        if s2 in synonyms: return synonyms[s2]
        key2 = s2.replace(" ", "")
        if key2 in no_space: return no_space[key2]

        # 包含匹配（优先长词）
        for cname in sorted(name_set, key=len, reverse=True):
            if cname in s2:
                return cname
        return None

    return canon


# -------------------- main --------------------

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--model-dir", required=True, help="LLaVA 模型目录（基座或合并后的 LoRA）")
    ap.add_argument("--val-ann", required=True, help="COCO instances_val2017.json")
    ap.add_argument("--val-img", required=True, help="COCO val2017 图像目录")
    ap.add_argument("--subset", type=int, default=50, help="评估前 N 张（0=全部）")
    ap.add_argument("--tokens", type=int, default=768, help="生成的最大新 token 数")
    ap.add_argument("--out", required=True, help="COCO 提交格式检测结果 json 路径")
    ap.add_argument("--max-objects", type=int, default=8, help="每图最多目标数")
    ap.add_argument("--nms-iou", type=float, default=0.6, help="NMS IoU 阈值")
    ap.add_argument("--min-conf", type=float, default=0.30, help="最小置信度")
    ap.add_argument("--show-raw", action="store_true", help="打印前几张的原始回复")
    args = ap.parse_args()

    device = "cuda" if torch.cuda.is_available() else "cpu"
    prefer_bf16 = torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8
    dtype = torch.bfloat16 if prefer_bf16 else torch.float16 if device == "cuda" else torch.float32

    print(f"[info] loading model from: {args.model_dir}")
    try:
        model = LlavaForConditionalGeneration.from_pretrained(args.model_dir, torch_dtype=dtype)
    except Exception:
        # 某些环境不支持 bf16，就回退 fp16
        model = LlavaForConditionalGeneration.from_pretrained(args.model_dir, torch_dtype=torch.float16)
    model.to(device).eval()
    proc = AutoProcessor.from_pretrained(args.model_dir)

    coco = COCO(args.val_ann)
    cats = coco.loadCats(coco.getCatIds())
    class_names = [c["name"] for c in cats]
    name2id = {c["name"].lower(): c["id"] for c in cats}
    canon_label = build_canon_label(name2id)
    allowed = set(name2id.keys())

    imgs = coco.dataset["images"]
    ids = [im["id"] for im in imgs]
    info = {im["id"]: (im["file_name"], im.get("width", 0), im.get("height", 0)) for im in imgs}
    if args.subset and args.subset > 0:
        ids = ids[:args.subset]
    print(f"[info] subset = {len(ids)} images")

    # 指令（不放 JSON 样例，减少“照抄模板”）
    instr = (
        "You are an object detection assistant. "
        "Return ONLY a valid JSON with key 'detections'. "
        'Each item: {"label": <one COCO class>, "box": [x1,y1,x2,y2], "confidence": [0,1]}. '
        "Coordinates are normalized to [0,1] with (x1,y1)=top-left and (x2,y2)=bottom-right. "
        f"At most {args.max_objects} objects. Do NOT repeat the same class or the same box. "
        "If two boxes IoU>0.6, keep the one with higher confidence. "
        "Use ONLY these labels (singular, English): " + ", ".join(class_names) + ". "
        'If nothing is found, return {"detections":[]}. '
        "Output JSON only."
    )

    def gen_and_decode(img, prompt, max_new_tokens):
        inputs = proc(images=img, text=prompt, return_tensors="pt")
        inputs = {k: (v.to(device) if hasattr(v, "to") else v) for k, v in inputs.items()}
        with torch.inference_mode():
            out = model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                do_sample=False,                # 关闭采样，稳定输出
                return_dict_in_generate=True
            )
        seq = out.sequences[0]
        gen_ids = seq[inputs["input_ids"].shape[-1]:]
        return proc.decode(gen_ids, skip_special_tokens=True).strip()

    all_dt = []
    ok_json = 0
    unk_counter = collections.Counter()
    t0 = time.time()

    for k, img_id in enumerate(ids, 1):
        fn, W, H = info[img_id]
        path = os.path.join(args.val_img, fn)
        img = Image.open(path).convert("RGB")

        messages = [{"role": "user", "content": [{"type": "image"}, {"type": "text", "text": instr}]}]
        prompt = proc.apply_chat_template(messages, add_generation_prompt=True)

        txt = gen_and_decode(img, prompt, args.tokens)

        # 可选：打印前 3 张图的原始回复
        if args.show_raw and k <= 3:
            print(f"==== RAW REPLY (image {k}: {fn}) ====")
            print(txt)

        js = extract_first_json(txt)
        dets_in = []
        if js is not None:
            try:
                obj = json.loads(js)
                if isinstance(obj, list):
                    obj = {"detections": obj}
                dets_in = obj.get("detections", []) if isinstance(obj, dict) else []
            except Exception:
                dets_in = []
        # 无论是否为空，都当作“可解析一次”
        ok_json += 1

        # 归一 + 过滤 + 置信度处理
        cleaned = []
        for d in dets_in if isinstance(dets_in, list) else []:
            raw_label = d.get("label", "")
            lab = canon_label(raw_label)
            if lab is None or lab not in allowed:
                # 统计未知标签但不报错
                if isinstance(raw_label, str) and raw_label:
                    unk_counter[raw_label.lower().strip()] += 1
                continue

            box = d.get("box", None)
            if not isinstance(box, (list, tuple)) or len(box) != 4:
                continue
            x1, y1, x2, y2 = [clamp01(b) for b in box]
            x1, x2 = min(x1, x2), max(x1, x2)
            y1, y2 = min(y1, y2), max(y1, y2)
            if not (x1 < x2 and y1 < y2):
                continue

            conf = coerce_conf(d.get("confidence", 0.0))
            if conf < args.min_conf:
                continue

            cleaned.append({"label": lab, "box": [x1, y1, x2, y2], "confidence": conf})

        # 类内 & 全局 NMS
        by_cls = {}
        for d in cleaned:
            by_cls.setdefault(d["label"], []).append(d)
        merged = []
        for lab, group in by_cls.items():
            merged.extend(nms_greedy(group, iou_thr=args.nms_iou))
        merged = nms_greedy(merged, iou_thr=args.nms_iou)

        # 同类仅保留最高分；限制最多数量
        best_by_cls = {}
        for d in merged:
            lab = d["label"]
            if (lab not in best_by_cls) or (d["confidence"] > best_by_cls[lab]["confidence"]):
                best_by_cls[lab] = d
        final_dets = sorted(best_by_cls.values(), key=lambda x: x["confidence"], reverse=True)[:args.max_objects]

        # 写 COCO 格式
        for d in final_dets:
            lab = d["label"]  # 已经是标准化的
            x1, y1, x2, y2 = d["box"]
            x, y, w, h = x1 * W, y1 * H, (x2 - x1) * W, (y2 - y1) * H
            all_dt.append({
                "image_id": int(img_id),
                "category_id": name2id[lab],
                "bbox": [float(x), float(y), float(w), float(h)],
                "score": float(clamp01(d["confidence"]))
            })

        print(f"[{k}/{len(ids)}] dt={len(final_dets)}")

    # 保存结果
    with open(args.out, "w") as f:
        json.dump(all_dt, f)
    print(f"[saved] detections -> {args.out}")
    jsucc = ok_json / max(1, len(ids))
    print(f"[info] JSON success rate: {ok_json}/{len(ids)} = {jsucc:.2%}")
    if unk_counter:
        topk = ", ".join([f"{k}:{v}" for k, v in unk_counter.most_common(5)])
        print(f"[info] skipped unknown labels (top): {topk}")
    print(f"[time] processed {len(ids)} images in {time.time() - t0:.1f}s")

    if len(all_dt) == 0:
        print("[warn] No detections recorded. mAP will be 0.0.")
        return

    # 评测
    res = coco.loadRes(args.out)
    e = COCOeval(coco, res, "bbox")
    e.evaluate(); e.accumulate(); e.summarize()
    mAP, AP50, AR100 = float(e.stats[0]), float(e.stats[1]), float(e.stats[8])
    print(f"[metrics] mAP@[.50:.95]={mAP:.4f} | AP50={AP50:.4f} | AR@100={AR100:.4f}")


if __name__ == "__main__":
    main()
————————————————————————————————————————————
python -u /home/vipuser/eval_llava_coco_det.py \
  --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_500imgs_merged \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 50 \
  --tokens 512 \
  --out /home/vipuser/coco/llava_dt_LORA_50.json \
  --show-raw
_________
# 方案A：用 sed 一把替换两种写法
sed -i 's/args\.show-raw/args.show_raw/g; s/args\.show\b/args.show_raw/g' /home/vipuser/eval_llava_coco_det.py
——————————————————————
python -u /home/vipuser/eval_llava_coco_det.py \
  --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_500imgs_merged \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 50 \
  --tokens 768 \
  --min-conf 0.30 \
  --nms-iou 0.60 \
  --max-objects 8 \
  --out /home/vipuser/coco/llava_dt_LORA_50.json \
  --show-raw

——————————————————————————————————————————
python -u /home/vipuser/eval_llava_coco_det.py \
  --model-dir /home/vipuser/llava-1.5-7b-hf \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 50 \
  --tokens 1024 \
  --max-objects 20 --min-conf 0.10 --nms-iou 0.5 \
  --out /home/vipuser/coco/llava_dt_BASE_50.json \
  --show-raw
——————————————————————————————————————————
# 原始模型（基线）
python -u /home/vipuser/eval_llava_coco_det.py \
  --model-dir /home/vipuser/llava-1.5-7b-hf \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 500 \
  --tokens 1024 --min-conf 0.30 --nms-iou 0.60 --max-objects 12 \
  --out /home/vipuser/coco/llava_dt_BASE_500.json --save-raw

# LoRA 合并后模型
python -u /home/vipuser/eval_llava_coco_det.py \
  --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_merged \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 500 \
  --tokens 1024 --min-conf 0.30 --nms-iou 0.60 --max-objects 12 \
  --out /home/vipuser/coco/llava_dt_LORA_500.json --save-raw
_______________
# 基线
~/miniforge3/envs/lf/bin/python -u /home/vipuser/eval_llava_coco_chat_SOLID.py \
  --model-dir /home/vipuser/llava-1.5-7b-hf \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 10 \
  --tokens 256 --min-conf 0.05 --nms-iou 0.60 --max-objects 12 \
  --out /home/vipuser/coco/smoke_BASE.json --save-raw
——————————————————
# LoRA（合并后：用 *_merged 这个目录）
python -u /home/vipuser/eval_llava_coco_chat_SOLID.py \
  --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_500imgs_merged \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 500 \
  --tokens 512 --min-conf 0.00 --nms-iou 0.60 --max-objects 50 \
  --out /home/vipuser/coco/LORA_500.json --save-raw
  ——————————————————————————————————————————————
# BASE
python -u /home/vipuser/eval_llava_coco_chat_SOLID.py \
  --model-dir /home/vipuser/llava-1.5-7b-hf \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 500 \
  --tokens 512 --min-conf 0.00 --nms-iou 0.60 --max-objects 50 \
  --out /home/vipuser/coco/BASE_500.json --save-raw

# LoRA（用 *_merged）
python -u /home/vipuser/eval_llava_coco_chat_SOLID.py \
  --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_500imgs_merged \
  --val-ann  /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 500 \
  --tokens 512 --min-conf 0.00 --nms-iou 0.60 --max-objects 50 \
  --out /home/vipuser/coco/LORA_500.json --save-raw
————————————————————————————————————————————————————————
# 例：用基座模型，对 COCO val2017 前 50 张做“自报准确率”
python -u /home/vipuser/selfreport_acc_llava.py \
  --model-dir /home/vipuser/llava-1.5-7b-hf \
  --val-img   /home/vipuser/coco/images/val2017 \
  --subset 50 \
  --tokens 256 \
  --out /home/vipuser/coco/self_acc_BASE_50.json \
  --save-raw
python -u /home/vipuser/selfreport_acc_llava.py \
  --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_500imgs_merged \
  --proc-dir  /home/vipuser/llava-1.5-7b-hf \
  --val-img   /home/vipuser/coco/images/val2017 \
  --subset 50 --tokens 256 \
  --out /home/vipuser/coco/self_acc_LORA_50.json --save-raw

——————————————————————————————————————————————————————
source ~/miniforge3/envs/lf/bin/activate
python -u /home/vipuser/unified_llava_det.py \
  --model-dir /home/vipuser/llava-1.5-7b-hf \
  --image /home/vipuser/coco/images/val2017/000000397133.jpg \
  --tokens 256 --max-objects 20 --device-map cuda \
  --out-img  /home/vipuser/coco/vis_BASE_397133.jpg \
  --out-json /home/vipuser/coco/vis_BASE_397133.json \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --save-raw

python -u /home/vipuser/unified_llava_det.py \
  --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_500imgs_merged \
  --proc-dir  /home/vipuser/llava-1.5-7b-hf \
  --image /home/vipuser/coco/images/val2017/000000397133.jpg \
  --tokens 256 --max-objects 20 --device-map cuda \
  --out-img  /home/vipuser/coco/vis_LORA_397133.jpg \
  --out-json /home/vipuser/coco/vis_LORA_397133.json \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --save-raw
source ~/miniforge3/envs/lf/bin/activate

python -u /home/vipuser/unified_llava_det.py \
  --model-dir /home/vipuser/llava-1.5-7b-hf \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 500 \
  --tokens 768 --min-conf 0.30 --nms-iou 0.60 --max-objects 12 \
  --out /home/vipuser/coco/llava_dt_BASE_500.json \
  --save-raw --device-map cuda

python -u /home/vipuser/unified_llava_det.py \
  --model-dir /home/vipuser/saves/lf_llava15_7b_coco_loraB_500imgs_merged \
  --proc-dir  /home/vipuser/llava-1.5-7b-hf \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --val-img  /home/vipuser/coco/images/val2017 \
  --subset 500 \
  --tokens 768 --min-conf 0.30 --nms-iou 0.60 --max-objects 12 \
  --out /home/vipuser/coco/llava_dt_LORA_500.json \
  --save-raw --device-map cuda

————————————————————————————————
python -u /home/vipuser/unified_llava_det.py \
  --model-dir /home/vipuser/llava-1.5-7b-hf \
  --image /home/vipuser/coco/images/val2017/000000397133.jpg \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --tokens 512 \
  --max-objects 20 \
  --min-conf 0.05 \
  --device-map cuda \
  --out-img  /home/vipuser/coco/vis_BASE_397133.jpg \
  --out-json /home/vipuser/coco/vis_BASE_397133.json \
  --save-raw

_____________________________
python -u /home/vipuser/yoloenv/yolo8_coco_export.py \
  --model yolov8s.pt \
  --val-img /home/vipuser/coco/images/val2017 \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --limit 50 --shuffle \
  --imgsz 640 --conf 0.25 --iou 0.7 --device 0 \
  --out /home/vipuser/coco/yolo8_dt_val50.json \
  --vis-dir /home/vipuser/coco/yolo8_vis_val50

  python -u /home/vipuser/yoloenv/eval_coco_json.py \
  /home/vipuser/coco/annotations/instances_val2017.json \
  /home/vipuser/coco/yolo8_dt_val50.json

——————————————————
# 激活你跑 YOLO 的环境
source ~/yoloenv/bin/activate

python -u /home/vipuser/yoloenv/yolo8_coco_export.py \
  --model yolov8x.pt \
  --val-img /home/vipuser/coco/images/val2017 \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --limit 50 --shuffle \
  --imgsz 960 --conf 0.01 --iou 0.6 --device 0 \
  --out /home/vipuser/coco/yolov8x_dt_val50.json \
  --vis-dir /home/vipuser/coco/yolov8x_vis_val50

python -u /home/vipuser/yoloenv/eval_coco_json.py \
  /home/vipuser/coco/annotations/instances_val2017.json \
  /home/vipuser/coco/yolov8x_dt_val50.json

python -u /home/vipuser/yoloenv/yolo8_coco_export.py \
  --model yolo11x.pt \
  --val-img /home/vipuser/coco/images/val2017 \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --limit 50 --shuffle \
  --imgsz 960 --conf 0.01 --iou 0.6 --device 0 \
  --out /home/vipuser/coco/yolo11x_dt_val50.json \
  --vis-dir /home/vipuser/coco/yolo11x_vis_val50
  
python -u /home/vipuser/yoloenv/yolo8_coco_export.py \
  --model yolov8x.pt \
  --val-img /home/vipuser/coco/images/val2017 \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --limit 50 --shuffle \
  --imgsz 960 \
  --conf 0.35 \
  --iou 0.5 \
  --device 0 \
  --out /home/vipuser/coco/yolov8x_dt_val50.json \
  --vis-dir /home/vipuser/coco/yolov8x_vis_val50
  
python -u /home/vipuser/yoloenv/yolo_coco_full_sota.py \
  --model yolo11x.pt \
  --val-img /home/vipuser/coco/images/val2017 \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --imgsz 1280 \
  --conf 0.001 \
  --iou 0.7 \
  --tta \
  --batch 8 \
  --agnostic \
  --extra-nms 0.7 \
  --max-det 300 \
  --device 0 \
  --out /home/vipuser/coco/yolo11x_dt_val2017_full.json

python -u /home/vipuser/yoloenv/yolo_coco_full_sota.py \
  --model yolo11x.pt \
  --val-img /home/vipuser/coco/images/val2017 \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --imgsz 1280 --conf 0.001 --iou 0.7 --tta \
  --batch 4 --workers 2 \
  --agnostic --extra-nms 0.7 --max-det 300 --device 0 \
  --out /home/vipuser/coco/yolo11x_dt_val2017_full.json

  
python -u /home/vipuser/yoloenv/eval_coco_json.py \
  /home/vipuser/coco/annotations/instances_val2017.json \
  /home/vipuser/coco/yolo11x_dt_val2017_full.json
————————————————————————————————————————————————————
随机抽 30 张渲染到新目录：
python -u /home/vipuser/yoloenv/vis_from_json.py \
  --val-img /home/vipuser/coco/images/val2017 \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --dets /home/vipuser/coco/yolo11x_dt_val2017_full.json \
  --vis-dir /home/vipuser/coco/yolo11x_vis_from_json \
  --vis-conf 0.35 \
  --limit 30
  ___________________
 yolo11s:
  python -u /home/vipuser/yoloenv/yolo_coco_full_sota.py \
  --model yolo11s.pt \
  --val-img /home/vipuser/coco/images/val2017 \
  --val-ann /home/vipuser/coco/annotations/instances_val2017.json \
  --imgsz 960 --conf 0.001 --iou 0.7 \
  --batch 8 --workers 4 \
  --agnostic --extra-nms 0.7 --max-det 300 --device 0 \
  --out /home/vipuser/coco/yolo11s_dt_val2017.json
评估：
python -u /home/vipuser/yoloenv/eval_coco_json.py \
  --ann /home/vipuser/coco/annotations/instances_val2017.json \
  --dt  /home/vipuser/coco/yolo11s_dt_val2017.json
————————————————————————————————————
yolo detect train \
  model=yolo11s.pt \
  data=/home/vipuser/yoloenv/coco80_local.yaml \
  imgsz=960 epochs=100 \
  batch=-1 device=0 workers=8 cache=ram \
  optimizer=auto cos_lr=True \
  lr0=0.003 lrf=0.12 momentum=0.937 weight_decay=0.0005 \
  hsv_h=0.015 hsv_s=0.7 hsv_v=0.4 \
  fliplr=0.5 flipud=0.0 translate=0.1 scale=0.5 shear=0.0 \
  mosaic=1.0 mixup=0.15 close_mosaic=10 copy_paste=0.0 \
  patience=30
